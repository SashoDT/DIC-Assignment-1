{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c15211c",
   "metadata": {},
   "source": [
    "# Map Reduce Task\n",
    "\n",
    "## Reading-in Preprocessed Data and Packages \n",
    " \n",
    "Install mrjob for it to work with the database.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eb9891c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviewer: A2VNYWOPJ13AFP, ASIN: 0981850006, Tokens: {'time', 'directions', 'cuisine', 'insight', 'yum', 'love', 'broadening', 'raichlen', 'page', 'food', 'provided', 'recipes', 'interpret', 'gift', 'simple', 'barbecue', 'husband', 'calls', 'kinds', 'open', 'produced', 'things', 'horizons', 'culture', 'make', 'making', 'trail', 'easy'}, Category: Patio_Lawn_and_Garde\n"
     ]
    }
   ],
   "source": [
    "import prep \n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5a7ff2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reviewerID': 'A2VNYWOPJ13AFP',\n",
       " 'asin': '0981850006',\n",
       " 'tokens': {'barbecue',\n",
       "  'broadening',\n",
       "  'calls',\n",
       "  'cuisine',\n",
       "  'culture',\n",
       "  'directions',\n",
       "  'easy',\n",
       "  'food',\n",
       "  'gift',\n",
       "  'horizons',\n",
       "  'husband',\n",
       "  'insight',\n",
       "  'interpret',\n",
       "  'kinds',\n",
       "  'love',\n",
       "  'make',\n",
       "  'making',\n",
       "  'open',\n",
       "  'page',\n",
       "  'produced',\n",
       "  'provided',\n",
       "  'raichlen',\n",
       "  'recipes',\n",
       "  'simple',\n",
       "  'things',\n",
       "  'time',\n",
       "  'trail',\n",
       "  'yum'},\n",
       " 'category': 'Patio_Lawn_and_Garde'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = prep.cleaned_reviews\n",
    "terms = prep.all_terms\n",
    "categories = prep.all_categories\n",
    "data[0] # overview "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f163067",
   "metadata": {},
   "source": [
    "## Calculate chi-square values\n",
    "\n",
    "**Recap of the variable names from the lecture:** \n",
    "- t ... term  \n",
    "- c ... category  \n",
    "- A ... number of documents in c which contain t  \n",
    "- B ... number of documents not in c which contain t  \n",
    "- C ... number of documents in c without t  \n",
    "- D ... number of documents not in c without t  \n",
    "- N ... total number of retrieved documents  (can be ommited for ranking)\n",
    "\n",
    "As we can see the definition of the chi-square test only counts the number of documents in which c or t are included but not the instances that t is contained in each single document. For this reason, we will edit the preprocessing to exclude multiple instances of each token in each review and also keep a set of all tokens and categories for later use. By doing this in the preprocessing we can reduce computation time. \n",
    "\n",
    "It may be very computationally intensive which is why we will try a multiprocessor approach. We probed the cluster of available CPU-cores in the current node by using the command \"nproc\". Furthermore, we used \"yarn node -list\" to list all nodes, \"yarn node -status <node-id>\" to check the number of virtual cores of different nodes which makes us believe that there are about **16 virtual cores** that each user can use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f54b6693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVariables(data, t, c): # getting variables for each term and category \n",
    "    A = B = C = D = 0\n",
    "    for lines in data: \n",
    "        if(c in lines[\"category\"]): \n",
    "            if(t in lines[\"tokens\"]): \n",
    "                A += 1 \n",
    "            else:\n",
    "                C += 1\n",
    "        else: \n",
    "            if(t in lines[\"tokens\"]): \n",
    "                B += 1 \n",
    "            else:\n",
    "                D += 1 \n",
    "    \n",
    "    return A,B,C,D\n",
    "\n",
    "\n",
    "from collections import defaultdict # useful for non-existing keys \n",
    "from heapq import nlargest \n",
    "from multiprocessing import Pool\n",
    "\n",
    "def chiSquare(data, terms, categories): \n",
    "    N = len(data) \n",
    "\n",
    "    # Calculate chi-square values for all unigram terms for each category: \n",
    "    ChiSquare = defaultdict(list)\n",
    "    for t in terms: \n",
    "        for c in categories: \n",
    "            A,B,C,D = getVariables(data, t, c)\n",
    "            ChiSquare[c].append(((N*(A*D-B*C)**2)/((A+B)*(A+C)*(B+D)*(C+D)), t))\n",
    "    \n",
    "    # ChiSquare_top75 = {\n",
    "    #     c: [t for value, t in nlargest(75, token_vals)]\n",
    "    #     for c, token_vals in ChiSquare.items()\n",
    "    # }\n",
    "    return ChiSquare #ChiSquare_top75\n",
    "\n",
    "def parallel_chiSquare(data, terms, categories, nprcs = 12): \n",
    "    \n",
    "    # Separate Terms: \n",
    "    terms = list(terms)\n",
    "    k,r = divmod(len(terms), nprcs) # k group size and r rest \n",
    "    inputs = [(data, terms[i * k + min(i, r):(i + 1) * k + min(i + 1, r)], categories) for i in range(nprcs)]\n",
    "\n",
    "    pool = Pool(processes= nprcs)\n",
    "    results = pool.starmap(chiSquare, inputs)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "\n",
    "    ChiSquare_top75 = {\n",
    "        c: [t for value, t in nlargest(75, token_vals)]\n",
    "        for c, token_vals in results.items()\n",
    "    }\n",
    "\n",
    "    return ChiSquare_top75\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9ece688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[{'time', 'directions', 'cuisine', 'insight', 'yum', 'love', 'broadening', 'raichlen', 'page', 'food', 'provided', 'recipes', 'interpret', 'gift', 'simple', 'barbecue', 'husband', 'calls', 'kinds', 'open', 'produced', 'things', 'horizons', 'culture', 'make', 'making', 'trail', 'easy'}],\n",
       "       [{'time', 'feels', 'bumps', 'nice', 'tires', 'experimentation', 'cable', 'edgeguard', 'precise', 'solid', 'handling', 'material', 'give', 'side', 'metal', 'arm', 'products', 'control', 'farther', 'distribution', 'good', 'great', 'maneuverability', 'pneumatic', 'flings', 'crappy', 'true', 'spreader', 'long', 'settings', 'left'}],\n",
       "       [{'falls', 'avoid', 'work', 'junction', 'leaks', 'sprinkler', 'bit', 'hose', 'pops', 'heads', 'fairly', 'poorly', 'designed', 'gilmour', 'spike', 'base', 'badly', 'metal', 'sprinklers', 'made', 'attachments', 'tighten', 'pointed', 'fix', 'useless', 'previous', 'plastic', 'wears', 'reviewer'}],\n",
       "       [{'time', 'waterin', 'corridors', 'work', 'large', 'system', 'bought', 'deere', 'areas', 'lawn', 'water', 'narrow', 'made', 'good', 'lot', 'works', 'john', 'part', 'pretty'}],\n",
       "       [{'lightweight', 'box', 'hard', 'return', 'buy', 'kinks', 'hose', 'unwieldy', 'exist', 'flexible', 'soft', 'heavy', 'thing', 'supposed', 'removed'}],\n",
       "       [{'time', 'shears', 'check', 'work', 'lock', 'machette', 'rail', 'rust', 'resharpen', 'removes', 'brush', 'fully', 'small', 'heavier', 'metal', 'lot', 'ready', 'thicker', 'initially', 'hook', 'tight', 'perform', 'woody', 'date', 'bank', 'ditch', 'session', 'note', 'cut', 'zombies', 'stemmed', 'side', 'spray', 'shipping', 'great', 'trees', 'works', 'bolts', 'free', 'multiple', 'plants', 'handle', 'washers', 'tool', 'clearing', 'paint', 'undead', 'grinding', 'nuts', 'cutting', 'weeds', 'bow', 'suggest', 'bit', 'encounter', 'remains', 'swings', 'plates', 'burrs', 'make', 'trail', 'seat', 'nicks', 'lopping', 'installing', 'find', 'improvement', 'ash', 'large', 'appropriately', 'blades', 'occasional', 'larger', 'handling', 'package', 'ward', 'compresses', 'easier', 'blade', 'wd', 'huge', 'nyloc', 'factory', 'sharpened'}],\n",
       "       [{'produces', 'design', 'lots', 'leaf', 'empty', 'lock', 'difficult', 'dry', 'holder', 'vacuuming', 'fairly', 'attached', 'bagger', 'mounted', 'vacuum', 'material', 'intended', 'cumbersome', 'usable', 'power', 'yard', 'copious', 'works', 'cord', 'powerful', 'type', 'typical', 'dust', 'handle', 'amounts', 'high', 'locked', 'improved'}],\n",
       "       [{'idea', 'design', 'corn', 'nice', 'grips', 'problem', 'ditching', 'back', 'genius', 'holders', 'twists', 'ditch', 'end', 'super', 'slip', 'eat', 'storage', 'problematic', 'regret', 'continues', 'flip', 'excited', 'annoying', 'thought', 'prong', 'corkscrew', 'approach', 'butter', 'twist', 'pivoting', 'prevent'}],\n",
       "       [{'time', 'cans', 'started', 'reduce', 'leaf', 'gallon', 'leaves', 'work', 'move', 'collection', 'finishing', 'back', 'piles', 'system', 'big', 'single', 'garbage', 'hog', 'doubt', 'continue', 'spent', 'helped', 'full', 'recommend', 'hurt', 'mulching', 'sped', 'saved', 'care', 'fabric', 'mulch', 'impressed', 'hours', 'year', 'dumping', 'highly', 'ton', 'bag', 'purchased'}],\n",
       "       [{'small', 'cut', 'heigth', 'back', 'edges', 'areas', 'adjust', 'make', 'manual', 'fine', 'area', 'roller', 'lawnmower', 'trimmer', 'difficult'}]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "test_array = np.array(data[0][\"tokens\"])\n",
    "for lines in data[1:10]: \n",
    "    test_array = np.vstack([test_array, lines[\"tokens\"]])\n",
    "\n",
    "test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b81d5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out = parallel_chiSquare(data, terms, categories)\n",
    "len(test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04661335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 b 3 \n",
      "2 a 2 \n",
      "1 c 1 \n"
     ]
    }
   ],
   "source": [
    "test_set = {}\n",
    "test_list = [\"b\", \"a\", \"c\"]\n",
    "test_list2 = [3, 2, 1]\n",
    "\n",
    "for i in range(3): \n",
    "    test_set.update({3-i:(test_list[i], test_list2[i])})\n",
    "\n",
    "for key, (t, v) in test_set.items(): \n",
    "    print(key, t, v, \"\\n\", end =\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "278245bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "b : 3\n",
      "a : 2\n",
      "c : 1\n",
      "1\n",
      "b : 3\n",
      "a : 2\n",
      "c : 1\n",
      "2\n",
      "b : 3\n",
      "a : 2\n",
      "c : 1\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict \n",
    "test_set = defaultdict(list)\n",
    "test_list = [\"b\", \"a\", \"c\"]\n",
    "test_list2 = [3, 2, 1]\n",
    "\n",
    "for i in range(3): \n",
    "    for j in range(3): \n",
    "        test_set[i].append((test_list[j], test_list2[j]))\n",
    "\n",
    "for key, values in test_set.items(): \n",
    "    print(key) \n",
    "    [print(t, \":\" ,v) for t,v in values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3527fae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "multiprocessing.cpu_count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
